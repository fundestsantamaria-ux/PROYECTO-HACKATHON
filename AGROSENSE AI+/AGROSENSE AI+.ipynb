{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cb19fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "AVANCE1:\n",
    "\n",
    "üå± AGRO-AI VISION PRO - Sistema de Diagn√≥stico de Enfermedades en Plantas\n",
    "==========================================================================\n",
    "Sistema avanzado de detecci√≥n de enfermedades con:\n",
    "- Transfer Learning (MobileNetV2)\n",
    "- Data Augmentation\n",
    "- Visualizaciones profesionales\n",
    "- Matriz de confusi√≥n\n",
    "- Predicciones con probabilidades\n",
    "- Exportaci√≥n de reportes\n",
    "- Interfaz mejorada para demo\n",
    "\n",
    "Autor: M.I.N.D RESEARCH GROUP\n",
    "Hackathon: [SAMSUMG INNOVATION CAMPUS]\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from google.colab import files\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "\n",
    "# ==========================================\n",
    "# üîß CONFIGURACI√ìN INICIAL\n",
    "# ==========================================\n",
    "print(\"=\"*60)\n",
    "print(\"üå± AGRO-AI VISION PRO - Inicializando Sistema\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Limpieza de configuraci√≥n anterior\n",
    "if os.path.exists('/root/.kaggle'):\n",
    "    !rm -rf /root/.kaggle\n",
    "    print(\"‚úÖ Configuraci√≥n anterior limpiada\")\n",
    "\n",
    "# Cargar credenciales de Kaggle\n",
    "print(\"\\nüì• Cargue su archivo kaggle.json:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "print(\"‚úÖ Credenciales de Kaggle configuradas\")\n",
    "\n",
    "# Descargar dataset\n",
    "print(\"\\nüì¶ Descargando dataset PlantVillage...\")\n",
    "!kaggle datasets download -d emmarex/plantdisease\n",
    "!unzip -q plantdisease.zip\n",
    "print(\"‚úÖ Dataset descargado y descomprimido\")\n",
    "\n",
    "# ==========================================\n",
    "# üìä CONFIGURACI√ìN DEL MODELO\n",
    "# ==========================================\n",
    "# Configuraci√≥n optimizada para balance entre precisi√≥n y velocidad\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224  # Tama√±o √≥ptimo para MobileNetV2\n",
    "IMG_WIDTH = 224\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Verificar ruta del dataset\n",
    "if os.path.exists('PlantVillage'):\n",
    "    data_dir = pathlib.Path(\"PlantVillage\")\n",
    "    print(\"‚úÖ Dataset PlantVillage encontrado\")\n",
    "else:\n",
    "    data_dir = pathlib.Path(\".\")\n",
    "    print(\"‚ö†Ô∏è Usando directorio actual\")\n",
    "\n",
    "# ==========================================\n",
    "# üé® DATA AUGMENTATION AVANZADO\n",
    "# ==========================================\n",
    "print(\"\\nüé® Configurando Data Augmentation...\")\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomBrightness(0.2),\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# üìÇ CARGA DE DATOS\n",
    "# ==========================================\n",
    "print(\"\\nüìÇ Cargando datos de entrenamiento...\")\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(\"üìÇ Cargando datos de validaci√≥n...\")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(f\"\\n‚úÖ {num_classes} clases detectadas\")\n",
    "print(f\"üìã Primeras 10 clases: {class_names[:10]}\")\n",
    "\n",
    "# Optimizaci√≥n de rendimiento\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# ==========================================\n",
    "# üèóÔ∏è CONSTRUCCI√ìN DEL MODELO CON TRANSFER LEARNING\n",
    "# ==========================================\n",
    "print(\"\\nüèóÔ∏è Construyendo modelo con Transfer Learning (MobileNetV2)...\")\n",
    "\n",
    "def create_model(num_classes, img_height, img_width):\n",
    "    \"\"\"\n",
    "    Crea un modelo de CNN usando Transfer Learning con MobileNetV2\n",
    "    pre-entrenado en ImageNet\n",
    "    \"\"\"\n",
    "    # Cargar modelo base pre-entrenado\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=(img_height, img_width, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Congelar las capas base inicialmente\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Construir el modelo completo\n",
    "    inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
    "    \n",
    "    # Data augmentation (solo en entrenamiento)\n",
    "    x = data_augmentation(inputs)\n",
    "    \n",
    "    # Preprocesamiento espec√≠fico de MobileNetV2\n",
    "    x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "    \n",
    "    # Modelo base\n",
    "    x = base_model(x, training=False)\n",
    "    \n",
    "    # Capas superiores personalizadas\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # Capa de salida\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "model, base_model = create_model(num_classes, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "# Compilar modelo\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]\n",
    ")\n",
    "\n",
    "print(\"\\nüìã Arquitectura del Modelo:\")\n",
    "model.summary()\n",
    "\n",
    "# ==========================================\n",
    "# üéØ CALLBACKS AVANZADOS\n",
    "# ==========================================\n",
    "print(\"\\nüéØ Configurando callbacks...\")\n",
    "\n",
    "# Early Stopping: Detiene el entrenamiento si no hay mejora\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Reduce Learning Rate: Reduce LR cuando la m√©trica se estanca\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Model Checkpoint: Guarda el mejor modelo\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr, checkpoint]\n",
    "\n",
    "# ==========================================\n",
    "# üöÄ FASE 1: ENTRENAMIENTO INICIAL\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ FASE 1: Entrenamiento con capas base congeladas\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history_phase1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# üîì FASE 2: FINE-TUNING\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîì FASE 2: Fine-tuning - Descongelando capas superiores\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Descongelar las √∫ltimas 50 capas del modelo base\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"Capas entrenables: {len([l for l in model.layers if l.trainable])}\")\n",
    "\n",
    "# Recompilar con learning rate m√°s bajo\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE/10),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]\n",
    ")\n",
    "\n",
    "# Continuar entrenamiento\n",
    "history_phase2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    initial_epoch=len(history_phase1.history['loss']),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Combinar historiales\n",
    "history = {\n",
    "    'accuracy': history_phase1.history['accuracy'] + history_phase2.history['accuracy'],\n",
    "    'val_accuracy': history_phase1.history['val_accuracy'] + history_phase2.history['val_accuracy'],\n",
    "    'loss': history_phase1.history['loss'] + history_phase2.history['loss'],\n",
    "    'val_loss': history_phase1.history['val_loss'] + history_phase2.history['val_loss'],\n",
    "}\n",
    "\n",
    "print(\"\\n‚úÖ Entrenamiento completado!\")\n",
    "\n",
    "# ==========================================\n",
    "# üìä VISUALIZACI√ìN DE RESULTADOS\n",
    "# ==========================================\n",
    "print(\"\\nüìä Generando visualizaciones...\")\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Visualiza el hist√≥rico de entrenamiento\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 0].plot(history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    axes[0, 0].plot(history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "    axes[0, 0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 1].plot(history['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, 1].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[0, 1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy comparison bar\n",
    "    final_train_acc = history['accuracy'][-1]\n",
    "    final_val_acc = history['val_accuracy'][-1]\n",
    "    axes[1, 0].bar(['Train', 'Validation'], [final_train_acc, final_val_acc], \n",
    "                   color=['#2ecc71', '#3498db'], width=0.5)\n",
    "    axes[1, 0].set_title('Final Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Accuracy')\n",
    "    axes[1, 0].set_ylim([0, 1])\n",
    "    for i, v in enumerate([final_train_acc, final_val_acc]):\n",
    "        axes[1, 0].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "    \n",
    "    # Metrics summary\n",
    "    axes[1, 1].axis('off')\n",
    "    metrics_text = f\"\"\"\n",
    "    üìä RESUMEN DE M√âTRICAS\n",
    "    {'='*40}\n",
    "    \n",
    "    üéØ Accuracy Final (Train): {final_train_acc:.4f}\n",
    "    ‚úÖ Accuracy Final (Val):   {final_val_acc:.4f}\n",
    "    \n",
    "    üìâ Loss Final (Train):     {history['loss'][-1]:.4f}\n",
    "    üìâ Loss Final (Val):       {history['val_loss'][-1]:.4f}\n",
    "    \n",
    "    üìà Mejor Val Accuracy:     {max(history['val_accuracy']):.4f}\n",
    "    üìâ Mejor Val Loss:         {min(history['val_loss']):.4f}\n",
    "    \n",
    "    üîÑ √âpocas Entrenadas:      {len(history['accuracy'])}\n",
    "    \"\"\"\n",
    "    axes[1, 1].text(0.1, 0.5, metrics_text, fontsize=11, \n",
    "                    family='monospace', verticalalignment='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"‚úÖ Gr√°fico guardado como 'training_history.png'\")\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# ==========================================\n",
    "# üéØ MATRIZ DE CONFUSI√ìN\n",
    "# ==========================================\n",
    "print(\"\\nüéØ Generando matriz de confusi√≥n...\")\n",
    "\n",
    "def generate_confusion_matrix(model, val_ds, class_names):\n",
    "    \"\"\"Genera y visualiza la matriz de confusi√≥n\"\"\"\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for images, labels in val_ds:\n",
    "        predictions = model.predict(images, verbose=0)\n",
    "        y_pred.extend(np.argmax(predictions, axis=1))\n",
    "        y_true.extend(labels.numpy())\n",
    "    \n",
    "    # Calcular matriz de confusi√≥n\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Si hay muchas clases, mostrar solo las 20 m√°s frecuentes\n",
    "    if len(class_names) > 20:\n",
    "        top_classes_idx = np.argsort(np.sum(cm, axis=1))[-20:]\n",
    "        cm = cm[top_classes_idx][:, top_classes_idx]\n",
    "        selected_classes = [class_names[i] for i in top_classes_idx]\n",
    "    else:\n",
    "        selected_classes = class_names\n",
    "    \n",
    "    # Visualizar\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=selected_classes, \n",
    "                yticklabels=selected_classes,\n",
    "                cbar_kws={'label': 'Frecuencia'})\n",
    "    plt.title('Matriz de Confusi√≥n - Top 20 Clases', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Predicci√≥n', fontsize=12)\n",
    "    plt.ylabel('Real', fontsize=12)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"‚úÖ Matriz guardada como 'confusion_matrix.png'\")\n",
    "    \n",
    "    # Reporte de clasificaci√≥n\n",
    "    print(\"\\nüìã Reporte de Clasificaci√≥n (Top 10 clases):\")\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, \n",
    "                                    output_dict=True, zero_division=0)\n",
    "    \n",
    "    # Mostrar las 10 mejores clases por F1-score\n",
    "    class_scores = [(name, data['f1-score']) for name, data in report.items() \n",
    "                    if name not in ['accuracy', 'macro avg', 'weighted avg']]\n",
    "    class_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\nüèÜ Top 10 Clases por F1-Score:\")\n",
    "    for i, (class_name, score) in enumerate(class_scores[:10], 1):\n",
    "        print(f\"{i:2d}. {class_name:40s} F1: {score:.4f}\")\n",
    "    \n",
    "    return cm, report\n",
    "\n",
    "cm, report = generate_confusion_matrix(model, val_ds, class_names)\n",
    "\n",
    "# ==========================================\n",
    "# üîç SISTEMA DE PREDICCI√ìN AVANZADO\n",
    "# ==========================================\n",
    "print(\"\\nüîç Configurando sistema de predicci√≥n...\")\n",
    "\n",
    "def diagnose_plant(model, image, class_names, top_k=5):\n",
    "    \"\"\"\n",
    "    Realiza diagn√≥stico de una planta con probabilidades detalladas\n",
    "    \"\"\"\n",
    "    # Preparar imagen\n",
    "    img_array = tf.expand_dims(image, 0)\n",
    "    \n",
    "    # Hacer predicci√≥n\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    probabilities = tf.nn.softmax(predictions[0]).numpy()\n",
    "    \n",
    "    # Obtener top K predicciones\n",
    "    top_indices = np.argsort(probabilities)[-top_k:][::-1]\n",
    "    top_probs = probabilities[top_indices]\n",
    "    top_classes = [class_names[i] for i in top_indices]\n",
    "    \n",
    "    return {\n",
    "        'predicted_class': top_classes[0],\n",
    "        'confidence': float(top_probs[0]),\n",
    "        'top_predictions': list(zip(top_classes, [float(p) for p in top_probs]))\n",
    "    }\n",
    "\n",
    "def visualize_prediction(image, result, class_names):\n",
    "    \"\"\"Visualiza una predicci√≥n con estilo profesional\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Imagen\n",
    "    ax1.imshow(image.astype(\"uint8\"))\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(f'Muestra Analizada', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Probabilidades\n",
    "    classes, probs = zip(*result['top_predictions'])\n",
    "    colors = plt.cm.RdYlGn(np.array(probs))\n",
    "    y_pos = np.arange(len(classes))\n",
    "    \n",
    "    bars = ax2.barh(y_pos, probs, color=colors)\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels([c.replace('___', ' - ').replace('_', ' ') for c in classes])\n",
    "    ax2.set_xlabel('Probabilidad', fontsize=12)\n",
    "    ax2.set_title('Top 5 Predicciones', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlim([0, 1])\n",
    "    \n",
    "    # A√±adir valores en las barras\n",
    "    for i, (bar, prob) in enumerate(zip(bars, probs)):\n",
    "        ax2.text(prob + 0.02, i, f'{prob:.2%}', \n",
    "                va='center', fontweight='bold')\n",
    "    \n",
    "    # A√±adir grid\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    ax2.invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ==========================================\n",
    "# üé¨ DEMO: DIAGN√ìSTICO EN TIEMPO REAL\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üé¨ DEMO: Sistema de Diagn√≥stico en Tiempo Real\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Tomar m√∫ltiples muestras para demo\n",
    "print(\"\\nüî¨ Analizando 6 muestras aleatorias del conjunto de validaci√≥n...\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "image_batch, label_batch = next(iter(val_ds))\n",
    "\n",
    "for idx in range(6):\n",
    "    image = image_batch[idx].numpy().astype(\"uint8\")\n",
    "    true_label = class_names[label_batch[idx]]\n",
    "    \n",
    "    # Hacer diagn√≥stico\n",
    "    result = diagnose_plant(model, image_batch[idx], class_names)\n",
    "    \n",
    "    # Visualizar\n",
    "    axes[idx].imshow(image)\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    # Determinar si es correcto\n",
    "    is_correct = result['predicted_class'] == true_label\n",
    "    color = '#2ecc71' if is_correct else '#e74c3c'\n",
    "    status = '‚úÖ CORRECTO' if is_correct else '‚ùå INCORRECTO'\n",
    "    \n",
    "    title = f\"{status}\\n\"\n",
    "    title += f\"Predicci√≥n: {result['predicted_class'].replace('___', ' - ').replace('_', ' ')}\\n\"\n",
    "    title += f\"Confianza: {result['confidence']:.1%}\\n\"\n",
    "    title += f\"Real: {true_label.replace('___', ' - ').replace('_', ' ')}\"\n",
    "    \n",
    "    axes[idx].set_title(title, fontsize=10, fontweight='bold', \n",
    "                        color=color, pad=10)\n",
    "\n",
    "plt.suptitle('üå± AGRO-AI VISION PRO - Resultados de Diagn√≥stico', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('demo_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úÖ Demo guardado como 'demo_predictions.png'\")\n",
    "\n",
    "# ==========================================\n",
    "# üíæ GUARDAR MODELO Y METADATOS\n",
    "# ==========================================\n",
    "print(\"\\nüíæ Guardando modelo y metadatos...\")\n",
    "\n",
    "# Guardar modelo\n",
    "model.save('agro_ai_vision_pro.keras')\n",
    "print(\"‚úÖ Modelo guardado como 'agro_ai_vision_pro.keras'\")\n",
    "\n",
    "# Guardar metadatos\n",
    "metadata = {\n",
    "    'model_name': 'AGRO-AI VISION PRO',\n",
    "    'version': '1.0.0',\n",
    "    'created_at': datetime.now().isoformat(),\n",
    "    'architecture': 'MobileNetV2 + Transfer Learning',\n",
    "    'image_size': [IMG_HEIGHT, IMG_WIDTH],\n",
    "    'num_classes': num_classes,\n",
    "    'class_names': class_names,\n",
    "    'final_accuracy': float(history['val_accuracy'][-1]),\n",
    "    'final_loss': float(history['val_loss'][-1]),\n",
    "    'best_accuracy': float(max(history['val_accuracy'])),\n",
    "    'epochs_trained': len(history['accuracy']),\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "}\n",
    "\n",
    "with open('model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"‚úÖ Metadatos guardados como 'model_metadata.json'\")\n",
    "\n",
    "# ==========================================\n",
    "# üìà REPORTE FINAL\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìà REPORTE FINAL DEL SISTEMA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "üéØ M√âTRICAS DE RENDIMIENTO:\n",
    "   ‚Ä¢ Accuracy Final (Validaci√≥n): {metadata['final_accuracy']:.2%}\n",
    "   ‚Ä¢ Mejor Accuracy:              {metadata['best_accuracy']:.2%}\n",
    "   ‚Ä¢ Loss Final:                  {metadata['final_loss']:.4f}\n",
    "   ‚Ä¢ √âpocas Entrenadas:           {metadata['epochs_trained']}\n",
    "\n",
    "üß† ARQUITECTURA:\n",
    "   ‚Ä¢ Modelo Base:                 {metadata['architecture']}\n",
    "   ‚Ä¢ Tama√±o de Imagen:            {IMG_HEIGHT}x{IMG_WIDTH}\n",
    "   ‚Ä¢ Clases Detectables:          {num_classes}\n",
    "   ‚Ä¢ Par√°metros Totales:          {model.count_params():,}\n",
    "\n",
    "üìä CAPACIDADES:\n",
    "   ‚Ä¢ Transfer Learning con ImageNet\n",
    "   ‚Ä¢ Data Augmentation avanzado\n",
    "   ‚Ä¢ Fine-tuning adaptativo\n",
    "   ‚Ä¢ Predicciones con Top-K\n",
    "   ‚Ä¢ Matriz de confusi√≥n\n",
    "   ‚Ä¢ Visualizaciones profesionales\n",
    "\n",
    "üíæ ARCHIVOS GENERADOS:\n",
    "   ‚Ä¢ agro_ai_vision_pro.keras     (Modelo entrenado)\n",
    "   ‚Ä¢ model_metadata.json          (Metadatos)\n",
    "   ‚Ä¢ training_history.png         (Gr√°ficos de entrenamiento)\n",
    "   ‚Ä¢ confusion_matrix.png         (Matriz de confusi√≥n)\n",
    "   ‚Ä¢ demo_predictions.png         (Demo de predicciones)\n",
    "   ‚Ä¢ best_model.keras             (Mejor checkpoint)\n",
    "\n",
    "üöÄ LISTO PARA PRODUCCI√ìN!\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Sistema AGRO-AI VISION PRO completamente entrenado!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ==========================================\n",
    "# üì• DESCARGAR ARCHIVOS\n",
    "# ==========================================\n",
    "print(\"\\nüì• ¬ødescargar los archivos generados? (y/n)\")\n",
    "download = input()\n",
    "\n",
    "if download.lower() == 'y':\n",
    "    files.download('agro_ai_vision_pro.keras')\n",
    "    files.download('model_metadata.json')\n",
    "    files.download('training_history.png')\n",
    "    files.download('confusion_matrix.png')\n",
    "    files.download('demo_predictions.png')\n",
    "    print(\"‚úÖ Archivos descargados exitosamente!\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Puede descargar los archivos manualmente desde el panel de archivos\")\n",
    "\n",
    "print(\"\\nüéâ ¬°Gracias por usar AGRO-AI VISION PRO!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
